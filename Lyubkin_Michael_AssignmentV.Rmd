---
title: "__Solutions for Assignment V: GitHub and the ticketmaster.com API__"
author: "__DS400 Data Science Project Management WS 20/21__"
date: "February 13, 2021"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
I worked together with Lana Kern (Student ID: 5395819), Martin Scheerer
(Student ID: 5631373) and Anton Höhl (Student ID: 5637078). I hereby assure that
my submission is in line with the *Code of Conduct* outlined on the lecture slides.

### __General Setup__

First I use ``opts_knit$set(root.dir = "")`` from the ``knitr`` package to set a 
working directory that will not cause problems in RMarkdown. Secondly, I clear my
workspace and load ( if needed) the relevant R packages that I need for the assignment.

```{r general_setup, warning=F, message=F}
rm(list = ls())  # clear workspace

# Setting my working directory in RMarkdown with the knitr package, instead of setwd() to not get any type of inconsistencies.

knitr::opts_knit$set(root.dir = "C:/Users/Lenovo/Desktop/Uni/Data Science Project Management/Assignments/Assignment5/DSPM_Assignment")

# Install relevant packages if needed

if (!require("tidyverse")) install.packages("tidyverse") # Generally needed
if (!require("httr")) install.packages("httr")  # For exercise 3
if (!require("rlist")) install.packages("rlist")  # For exercise 3
if (!require("jsonlite")) install.packages("jsonlite") # For exercise 3
if (!require("maps")) install.packages("maps") # For exercise 5

# Load the respective packages

library(tidyverse)
library(httr)
library(rlist)
library(jsonlite)
library(maps)

```

## __Exercise 1: Setting up a new GitHub repository__

All the necessary steps have been executed.

The project's repository can be found on Github under the following Link:
https://github.com/michaellyubkin/DSPM_Assignment


## __Exercise 2: Getting to know the API__

I treat the API key as a secret token by creating a separate R file that cointains the API key. With the base function ``source()``, I can simply import that inforamtion without explicitly showing it in the main file. 

Furthermore, the API key should not be seen on a public Github repository, therefore I include it in the  _.gitignore_ text document. The exact name of the ignorable file as well as the correct file ending should be stated within that document. Thta is exactly what I did to secure the information of my API key.


```{r source_API_key}
source("API_key.R")

```


## __Exercise 3: Interacting with the API - the basics__

The neccessary packages have been loaded in the general setup and not in this section. I prefer it to be at the beginning, as I think it is more organised and
easy to understand for the reader.

```{r API_requests_first_page, warning=F}
# I perform a GET request that searches for event venues in Germany. The abbreviation that is use to retrive information from Germany is the argument countryCode="DE".
# It is important to set the argument locale = "*" to match all locales.

response <- GET("https://app.ticketmaster.com/discovery/v2/venues.json?",
                  query=list(apikey=API_key,
                             countryCode="DE",
                             locale="*"))

# When working with API's it is always important to check whether the GET request was succesfull.
# This is why I use function status_code().

status_code(response)

# The status code is 200, which tells us that our GET request ran without problems.

# I extract the content from the response variable with the function content() asnd specifiying the argument as="text. Furthermore I need to parse this from json format to a R list.
# For this purpose, I use the fromJSON() function from the jsonlite package.

json <- jsonlite::fromJSON(content(x=response, as = "text"))

# The retrived object is a List of 3. One list is called _embedded. The other two Lists are called _links and page. In the _embedded List, there is a datframe venues that holds 19 columns and 20 rows. This is exactly what we wanted for our exercise. 

# To get our asked information about venues in Germany, I simply use $ to get the information from that List.

venues <- json$`_embedded`$venues

# As the given data frame has 19 columns, buit we need only 7 columns, I create a new data frame venue_data.

venue_data <- 0

# The data frame venues_data should have the respective columns from the venues data frame. Fir this step it is highly important to use the $ sign multiple times. Some variables show a value of NULL if only use with one $ sign.

venue_data$name <- venues$name
venue_data$city <- venues$city$name
venue_data$postalCode <- venues$postalCode
venue_data$address <- venues$address$line1
venue_data$url <- venues$url

# The longitude and latitude columns should not be a in a character format but instead of dbl format.

venue_data$longitude <- as.double(venues$location$longitude) 
venue_data$latitude <- as.double(venues$location$latitude)

# Venues_data is still a List of 8 but should be a datframe with 7 columns.

# I transform it form List to a data fraem with the as.data.frame() function.

venue_data <- as.data.frame(venue_data)

# The transformation causes R to add one column X0 which is useless for our excercise.
# I remove it to have the desired data frame.

venue_data <- venue_data[,-1]

# The resulting data frame takes on the following form:

glimpse(venue_data)

```

## __Exercise 4: Interacting with the API - advanced__

Check the API documentation under the section Venue Search. How can you request the venues from
the remaining results pages?

I write a ``for`` loop that iterates through the pages and I write a ``GET()`` request for all venues not just the first page with 20 venues.

```{r count_all_venues}
#Retrive information from the json file that shows me the total number of values.

n <- as.numeric(json[['page']][['totalElements']])
n

```

There are 12238 venues in Germany. This can be also seen on the website of the API. 

In order to understand how I should code my ``for`` loop, I first need to understand how many iterations the ``for`` loop is going to have.

```{r preparing_for_loop}
# I divide the number of venues trough 500 pages. I experiminted with how much venues can be retrieved per iteration and 500 is the largest it can go without
# causing errors.

pages <- floor(n/500)
pages 

# 24 full pages can be retrieved

# Of course 24*500= 12000 yields only 12000 venues, but we know there are 12238 venues.

# Caluclatin the remaining pages which should account to 238 venues!
remainder <- n-500*floor(n/500)
remainder

```

I tried multiple ``for`` loops also in combination with the ``list.stack()`` function. However, when writing ``for`` loops, I need to pay attention to multiple things.
First, it needs to be computationally efficient, just as we discussed in Assignment 3. Secondly, for loops should be easily understood by other readers and therefore as easy as possible and
the code should not be too long to avoid erros.

For this task, I went with a ``for`` loop that is not computationally efficient, as with ``rbind()`` it constantly needs to rearrange the size of the resulting data frame. I tried it with the  ``list.stack()`` function that would allow me to pre-specifiy a data frame with the correct rows and columns, so that the only thing I needed to do, was filling the rows. But sadly, I was not able to correctlly code that ``for`` loop.

Instead, I will use ``rbind()`` function which is less compuationally efficient, but for my taks, commpuationally acceptable and the resulting ``for`` loop is short and easy understandable and iterates relatively quick nonetheless.

If I had a more compuationally complex task, I would stick with the ``list.stack()`` function and try it with this function.

But, for exercise 4, the following ``for`` loop is sufficent.

```{r for_loop_all_venues}
# Creating a size_500 object, so it can used as a argument in the GET() function. This allows us to get 500 venues per page.
size_500 <- 500

# Creating a empty dataframe that will be merged with the resulting venues.

all_venues <- data.frame()

# As I use the rbind() function, it is unneccessary to distinguish betwenn full pages and the remainding venues. Therefore I need to iterate through 25 pages, whereby the last page only consists of 238 venues.

pages <- pages + 1

# Adding the size argument and setting it to 500, and I add the page argument, as I want to iteate through all pages.

for (i in 0:pages) {
  res_venues <- GET("https://app.ticketmaster.com/discovery/v2/venues.json?", 
                    query = list(apikey = API_key,
                                 countryCode = "DE",
                                 locale="*",
                                 page   = i,
                                 size=size_500))
  
  json_all <- jsonlite::fromJSON(content(x=res_venues, as = "text"))
  
  venues_all <- json_all$`_embedded`$venues
  
  # Creating a dataframe, with the length of the respective venues.
  
  venues_data_all <- tibble(
    name= character(length(venues_all$name)),
    city=character(length(venues_all$name)),
    postalCode=character(length(venues_all$name)),
    address=character(length(venues_all$name)),
    url=character(length(venues_all$name)),
    longitude=character(length(venues_all$name)),
    latitude=character(length(venues_all$name)))
  
  venues_data_all$name <- venues_all$name
  venues_data_all$city <- venues_all$city$name
  venues_data_all$postalCode <- venues_all$postalCode
  venues_data_all$address <- venues_all$address$line1
  venues_data_all$url <- venues_all$url
  venues_data_all$longitude <- as.double(venues_all$location$longitude)
  venues_data_all$latitude <- as.double(venues_all$location$latitude)   
  
  # Using the rbind() function to bind the resulting data frame with our empty datframe in the first iteration. In the second iteration, it will have 500 rows which will be binded to the 500 rows of the second iteration. This process repeats itself until we hit the 25th page.
    
  all_venues <- rbind(all_venues, venues_data_all)
  
  # Setting Sys.sleep() to 2 seconds to avoid sening to many requests per second. This is in line with the respective API laws.
  
  Sys.sleep(2)
}
```

The resulting dataframe does not have the name _venue_data_ as in the exercise solution. This is beacuse _venue_data_ is already a name for the resulting data frame in exercise 3.

The data frame ``all_venues`` takes on the following form:

```{r glimpse_all_venues}
glimpse(all_venues)
head(all_venues, 5)
tail(all_venues,5)

```

## __Exercise 5: Visualizing the extracted data__

```{r preparing_for_map}

map_data_venues <- all_venues

map_data_venues$long <- ifelse(between(map_data_venues$longitude, 5.866944, 15.043611), 
                          map_data_venues$longitude, NA)

map_data_venues$lat <- ifelse(between(map_data_venues$latitude, 47.271679, 55.0846), 
                          map_data_venues$latitude, NA)

sum(is.na(map_data_venues$long))
sum(is.na(map_data_venues$lat))

```


```{r map}

ggplot() + 
  geom_polygon(
        aes(x = long, y = lat, group = group), 
        data = map_data("world", region = "Germany"),
        fill = "grey90",color = "black") +
  theme_void() + 
  coord_quickmap() +
  geom_point(data = map_data_venues, aes(x = long, y = lat), size = 0.5) +
  labs(title = "Event locations across Germany", 
       caption = "Source: ticketmaster.com") + 
  theme(title = element_text(size=8, face='bold'),
        plot.caption = element_text(face = "italic"))


```

## __Exercise 6: Event locations in other countries__

```{r exercise_3}

response <- GET("https://app.ticketmaster.com/discovery/v2/venues.json?",
                  query=list(apikey=API_key,
                             countryCode="CZ",
                             locale="*"))

status_code(response)

json <- jsonlite::fromJSON(content(x=response, as = "text"))

venues <- json$`_embedded`$venues

venues_data <- 0

venues_data$name <- venues$name
venues_data$city <- venues$city$name
venues_data$postalCode <- venues$postalCode
venues_data$address <- venues$address$line1
venues_data$url <- venues$url
venues_data$longitude <- as.double(venues$location$longitude)
venues_data$latitude <- as.double(venues$location$latitude)

venues_data <- as.data.frame(venues_data)

venues_data <- venues_data[,-1]

glimpse(venues_data)

venues_data$longitude[venues_data$longitude==0] <- NA
venues_data$latitude[venues_data$latitude==0] <- NA

```

```{r exercise_4}

n <- as.numeric(json[['page']][['totalElements']])
pages <- floor(n/500)

remainder <- n-500*floor(n/500)

size_500 <- 500

all_venues <- data.frame()

pages <- pages + 1

for (i in 0:pages) {
  res_venues <- GET("https://app.ticketmaster.com/discovery/v2/venues.json?", 
                    query = list(apikey = API_key,
                                 countryCode = "CZ",
                                 locale="*",
                                 page   = i,
                                 size=size_500))
  
  json_all <- jsonlite::fromJSON(content(x=res_venues, as = "text"))
  
  venues_all <- json_all$`_embedded`$venues
  
  venues_data_all <- tibble(
    name= character(length(venues_all$name)),
    city=character(length(venues_all$name)),
    postalCode=character(length(venues_all$name)),
    address=character(length(venues_all$name)),
    url=character(length(venues_all$name)),
    longitude=character(length(venues_all$name)),
    latitude=character(length(venues_all$name)))
  
  venues_data_all$name <- venues_all$name
  venues_data_all$city <- venues_all$city$name
  venues_data_all$postalCode <- venues_all$postalCode
  venues_data_all$address <- venues_all$address$line1
  venues_data_all$url <- venues_all$url
  venues_data_all$longitude <- as.double(venues_all$location$longitude)
  venues_data_all$latitude <- as.double(venues_all$location$latitude)   

  
  all_venues <- rbind(all_venues, venues_data_all)
  
  
  Sys.sleep(2)
}

```

```{r preparing_data_map}

map_data_venues <- all_venues

map_data_venues$longitude[map_data_venues$longitude==0] <- NA
map_data_venues$latitude[map_data_venues$latitude==0] <- NA

map_data_venues <- map_data_venues %>%
  filter(name !="TEST Venue Product Support" & name !="Divadlo Na Orlí")

sum(is.na(map_data_venues$long))
sum(is.na(map_data_venues$lat))


```

```{r map_sweden}
ggplot() + 
  geom_polygon(
        aes(x = long, y = lat, group = group), 
        data = map_data("world", region = "Czech Republic"),
        fill = "grey90",color = "black") +
  theme_void() + 
  coord_quickmap() +
  geom_point(data = map_data_venues, aes(x = longitude, y = latitude), size = 0.5) +
  labs(title = "Event locations across Czech Republic", 
       caption = "Source: ticketmaster.com") + 
  theme(title = element_text(size=8, face='bold'),
        plot.caption = element_text(face = "italic"))


```